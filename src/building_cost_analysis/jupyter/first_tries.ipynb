{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7bb4f5-0781-42d7-92eb-5ec56babdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 3 parts:\n",
    "# kostenschätzung\n",
    "# ausgabenberechnung (bilanz berechnen => schätzung vs. tatsächliche kosten)\n",
    "# kostenvergleich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36241b-71ca-49d4-b865-6814cb43727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gewerke = r'C:\\Users\\Michael\\Google Drive\\Projekt_Palast\\Finanzen\\Kostenberechung\\Kostenberechnung_Gewerke.xlsx'\n",
    "df_gewerke = pd.read_excel(path_gewerke, skiprows=1, converters={'ID':str})\n",
    "# bring all position descriptions to column 'Beschreibung'\n",
    "df_gewerke.loc[~df_gewerke['Unnamed: 3'].isnull(), 'Beschreibung'] = df_gewerke.loc[~df_gewerke['Unnamed: 3'].isnull()]['Unnamed: 3']\n",
    "df_gewerke.loc[~df_gewerke['Unnamed: 4'].isnull(), 'Beschreibung'] = df_gewerke.loc[~df_gewerke['Unnamed: 4'].isnull()]['Unnamed: 4']\n",
    "# remove all columns except ID and Beschreibung\n",
    "df_gewerke = df_gewerke[['ID', 'Beschreibung']]\n",
    "\n",
    "\n",
    "# TODO plausibility checks ID == np.nan\n",
    "# TODO plausibility check ascending ids!\n",
    "# TODO check if all ids < level remain constant inside the group ( for example 10.10, 10.20 10.30 ok, 10.10, 20.10, 10.20 wrong!)\n",
    "# maybe this makes no sense!.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a9fe5-d9b5-4ffd-891f-ea8cb0fc4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_with_extended_id_cols(df, level=None):\n",
    "    df['ID'] = df['ID'].astype(str)\n",
    "    df['level'] = df['ID'].str.count('\\\\.')\n",
    "    df['id_list'] = df['ID'].str.split('\\\\.')\n",
    "    max_level = df['level'].max()\n",
    "    print(max_level)\n",
    "    for cur_level in range(max_level+1):\n",
    "        df[f'id_{cur_level}'] = np.nan\n",
    "        mask_level = df['level'] >= cur_level\n",
    "        df.loc[mask_level, f'id_{cur_level}'] = df.loc[mask_level]['id_list'].apply(lambda x: x[cur_level])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add982c2-7af5-4b4c-8575-71d0bff60393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gewerke = get_df_with_extended_id_cols(df_gewerke)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd7ed2-eea0-4c58-860a-e5127a9ace59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation total cost\n",
    "dir_angebote = r'C:\\Users\\Michael\\Google Drive\\Projekt_Palast\\Finanzen\\Kostenberechung\\Analyse'\n",
    "# TODO this will be manually chooseable in the dashapp\n",
    "sheet_nr = 1\n",
    "import os\n",
    "import glob\n",
    "files = os.listdir(dir_angebote)\n",
    "print(files)\n",
    "\n",
    "list_df_offers = []\n",
    "for file_path in files:\n",
    "    if not file_path.endswith('.xlsx') or file_path.startswith('~'):\n",
    "        continue\n",
    "    path_angebot = os.path.join(dir_angebote, file_path)\n",
    "    df_angebot = pd.read_excel(path_angebot, skiprows=3, converters={'ID':str}, sheet_name=sheet_nr)\n",
    "    df_angebot = df_angebot[df_angebot.columns.drop(list(df_angebot.filter(regex='Unnamed')))]\n",
    "    df_angebot = df_angebot.loc[~df_angebot['ID'].isnull()]\n",
    "    df_angebot.loc[:, 'ID'] = df_angebot['ID'].astype(str)\n",
    "    # add brutto column\n",
    "    if \"Brutto\" not in df_angebot.columns:\n",
    "        df_angebot[\"Brutto\"] = \"Nein\"\n",
    "    # add UST everywhere Brutto == Nein\n",
    "    df_angebot[\"price_brutto\"] = df_angebot[\"Gesamtpreis\"]\n",
    "    df_angebot[\"factor\"] = 1.0\n",
    "    df_angebot.loc[df_angebot[\"Brutto\"] != \"Ja\", \"factor\"] = 1.2\n",
    "    df_angebot.loc[:, \"price_brutto\"] =  df_angebot[\"price_brutto\"] * df_angebot[\"factor\"]\n",
    "    \n",
    "    # TODO add source sheet as well\n",
    "    df_angebot.loc[:, 'file_source'] = file_path\n",
    "    list_df_offers.append(df_angebot)\n",
    "\n",
    "df_offers = pd.concat(list_df_offers)\n",
    "max_level = df_gewerke['level'].max()\n",
    "df_offers = get_df_with_extended_id_cols(df_offers, max_level)\n",
    "\n",
    "#TODO check if preisangaben für subposition + position gemacht wurde => das unterstützen wir nicht zurzeit (könnte man aber ändern)\n",
    "# TODO combine with estimates (schätzungen excel files, immer nur schätzung verwenden wenn kein angebot vorhanden)\n",
    "# \n",
    "df_offers.groupby(['id_0']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b337bb-679c-4949-83df-1f11e8206513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gewerke.to_csv('./data/temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596c355-0c4e-40e3-b309-6382484408fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offers.to_csv('./data/temp_angebot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ab49c-953f-499f-9e04-70d2f97495e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO determine duplicated positions\n",
    "duplicated_id = df_offers[df_offers[['ID']].duplicated()]['ID'].values\n",
    "print('Duplikate:')\n",
    "df_offers.loc[df_offers['ID'].isin(duplicated_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892966c4-a661-4185-a507-a28de8a0fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rolled_up_sum_to_df(df_combined):\n",
    "    max_level = df_combined['level'].max()\n",
    "    list_level_sums = []\n",
    "    for cur_level in range(max_level+1):\n",
    "        list_ids = []\n",
    "        for lev in range(cur_level + 1):\n",
    "            list_ids.append(f'id_{lev}')\n",
    "        df_level_count = df_combined.groupby(list_ids).count()\n",
    "        df_level_sum = df_combined.groupby(list_ids).sum()\n",
    "        df_level_sum['summed_up'] = df_level_sum['price_brutto']\n",
    "        df_level_count['prices_existing'] = False\n",
    "        df_level_count.loc[df_level_count['price_brutto'] != 0, 'prices_existing'] = True\n",
    "        df_level_sum = df_level_sum[['summed_up']].combine_first(df_level_count[['prices_existing']])\n",
    "        df_level_sum['level'] = cur_level\n",
    "        df_level_sum = df_level_sum.reset_index()\n",
    "        df_level_sum['ID'] = df_level_sum['id_0']\n",
    "        for lev in range(1, cur_level + 1):\n",
    "            df_level_sum['ID'] += \".\" + df_level_sum[f'id_{lev}']\n",
    "\n",
    "        list_level_sums.append(df_level_sum)\n",
    "    df_rolled_up_sum = pd.DataFrame()\n",
    "\n",
    "    for df_sum in list_level_sums:\n",
    "        df_rolled_up_sum = df_rolled_up_sum.combine_first(df_sum.set_index('ID'))\n",
    "    df_ret = df_combined.combine_first(df_rolled_up_sum[['prices_existing', 'summed_up']])\n",
    "    df_ret.to_csv('./data/summed_up_test.csv')\n",
    "    return df_ret\n",
    "\n",
    "df_combined = df_offers.set_index('ID').combine_first(df_gewerke.set_index('ID'))\n",
    "df_combined.to_csv('./data/combined_test.csv')\n",
    "\n",
    "# TODO calculate prices for each level\n",
    "df_combined = append_rolled_up_sum_to_df(df_combined)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fc998-51f3-47a0-ae2e-78493de912bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_level = df_combined['level'].max()\n",
    "list_ids = []\n",
    "for lev in range(max_level + 1):\n",
    "    list_ids.append(f'id_{lev}')\n",
    "    df_combined[f'id_{lev}'] = df_combined[f'id_{lev}'].astype(float).fillna(0)\n",
    "df_sorted = df_combined.sort_values(list_ids)\n",
    "df_combined.sort_values(list_ids).to_csv('./data/sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae38373-31d7-48ea-83c6-41f7fb609300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110b543-0c2a-4b49-b572-4e9e6af17e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f87cf-71ad-49bd-8501-108e9b0b5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.loc[df_sorted['level'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db34f1b-5bf8-450d-b763-b7010578c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO determine missing positions\n",
    "def get_missing_positions(df_sorted):\n",
    "    max_level = df_sorted['level'].max()\n",
    "    list_ids = []\n",
    "    df_missing = df_sorted.copy()\n",
    "    df_missing['display_missing'] = False\n",
    "    df_missing['upper_level_missing'] = False\n",
    "    df_missing['upper_level_inserted'] = False\n",
    "    for lev in range(max_level + 1):\n",
    "        mask_cur_level = (df_missing['level'] == lev) & (df_missing['prices_existing'] == False) & (df_missing['upper_level_missing'] == False)\n",
    "        df_missing.loc[mask_cur_level, 'display_missing'] = True\n",
    "        # set upper level missing\n",
    "        for row_id, missing_row in df_missing[mask_cur_level].iterrows():\n",
    "            mask = (df_missing['level'] > lev)\n",
    "            for sublev in range(lev+1):\n",
    "                mask = mask & (df_missing[f'id_{sublev}'] == missing_row[f'id_{sublev}'])\n",
    "            df_missing.loc[mask, 'upper_level_missing'] = True\n",
    "        # set upper level inserted\n",
    "        mask_inserted = (df_missing['level'] == lev) & (~df_missing['price_brutto'].isnull())\n",
    "        for row_id, missing_row in df_missing[mask_inserted].iterrows():\n",
    "            mask = (df_missing['level'] > lev)\n",
    "            for sublev in range(lev+1):\n",
    "                mask = mask & (df_missing[f'id_{sublev}'] == missing_row[f'id_{sublev}'])\n",
    "            df_missing.loc[mask, 'upper_level_inserted'] = True\n",
    "    return df_missing.loc[(df_missing['display_missing'] == True) & ((df_missing['upper_level_inserted'] == False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905699c-58e4-4992-8c2a-f67e59405b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298712d6-4efd-4d93-abf4-0854130647a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_missing_positions(df_sorted).to_csv('./data/missing.csv')\n",
    "get_missing_positions(df_sorted)[['Beschreibung']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95e2e9-e779-4f13-936b-4b1c6a6bba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Gesamtpreis Brutto column einfügen\n",
    "df_sorted.groupby(['id_1']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431eaa66-bddd-4844-b677-00bf7a6b187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.loc[df_sorted['level'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadbea1-465e-4e66-815b-2cd7d169d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.loc[df_sorted['level'] == 0][['summed_up']].sum() * 1.0# 5 % sicherheitsreserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f6791-0baf-465a-b16f-7c2546d40318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.loc[df_sorted['level'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061e320-813f-4c87-8a20-07cad432760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.loc[df_sorted['level'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e9141-ec07-4906-b22c-49b1423845a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
